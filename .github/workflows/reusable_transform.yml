on:
  workflow_call:
    inputs:
      ENVIRONMENT:
        required: true
        type: string
      DB_OVERRIDE:
        required: false
        type: string
        default: ""
      FULL_REFRESH:
        required: true
        type: string
      DBT_CUSTOM_IMAGE:
        required: true
        type: string
      BRANCH_NAME:
        type: string
      DBT_CLOUD:
        required: false
        type: string
        default: "false"
      DEPLOY_GD_MODELS:
        required: false
        type: string
        default: "true"

jobs:
  reusable_transform:
    name: transform
    runs-on: ubuntu-latest
    environment: ${{ inputs.ENVIRONMENT }}
    container: ${{ inputs.DBT_CUSTOM_IMAGE }}
    env:
      FR_ARG: ${{ inputs.FULL_REFRESH == 'true' && '--full-refresh' || '' }}
      DBT_DB_PASS: "${{ secrets.DB_PASS }}"
      MOTHERDUCK_TOKEN: "${{ secrets.MOTHERDUCK_TOKEN }}"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ inputs.BRANCH_NAME }}

      - name: Setup Environment
        shell: bash
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          cd $SRC_DATA_PIPELINE
          # dbt packages are installed during build of docker image to workdir
          ln -s $IMAGES_WORKDIR/dbt_packages dbt_packages
          mkdir -p ~/.gooddata
          echo ${{ secrets.GOODDATA_PROFILES_FILE }} | base64 --decode > ~/.gooddata/profiles.yaml

      - name: Run Transform
        shell: bash
        timeout-minutes: 15
        if: ${{ inputs.DBT_CLOUD == 'false' }}
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          make transform

      - name: Archive dbt run
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dbt-run-files-${{ github.sha }}-${{ inputs.ENVIRONMENT }}-${{ inputs.DB_OVERRIDE || 'default' }}
          path: |
            ${{ vars.SRC_DATA_PIPELINE }}/target

      - name: Run Transform (dbt Cloud)
        shell: bash
        timeout-minutes: 15
        if: ${{ inputs.DBT_CLOUD == 'true' }}
        env:
          DBT_TOKEN: "${{ secrets.DBT_TOKEN }}"
          DBT_ALLOWED_DEGRADATION: "${{ vars.DBT_ALLOWED_DEGRADATION || '20' }}"
          # GITHUB_ variables are reserved by GitHub.
          #   The gooddata-dbt accepts equivalent GOODDATA_ variables
          # There is no way how to expose these variables AFTER MERGE (on push)
          #   There is no link between merged commit and original pull request,
          #   also because someone can push to main branch directly
          #   TODO: Let's ignore it now and think about it later
          # dbt Cloud checkouts the commit specified by GOODDATA_GITHUB_SHA
          # TODO: what if a pull request is created from a fork?
          GOODDATA_GITHUB_SHA: "${{ github.event.pull_request.head.sha == '' && github.sha || github.event.pull_request.head.sha }}"
          # Used to post comments to pull requests
          GOODDATA_GITHUB_TOKEN: "${{ secrets.BOT_GITHUB_TOKEN }}"
          GOODDATA_GITHUB_PULL_REQUEST_ID: "${{ github.event.pull_request.number }}"
          GOODDATA_GITHUB_ACTOR: "${{ github.actor }}"
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          make transform_cloud

      - name: Provision GoodData workspaces
        shell: bash
        if: ${{ inputs.DEPLOY_GD_MODELS == 'true' }}
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          make provision_workspaces

      - name: Register Data Sources in GoodData
        shell: bash
        if: ${{ inputs.DEPLOY_GD_MODELS == 'true' }}
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          make register_data_sources

      - name: Deploy GoodData LDM
        shell: bash
        if: ${{ inputs.DEPLOY_GD_MODELS == 'true' }}
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          make deploy_ldm

      - name: Invalidate GoodData caches
        shell: bash
        run: |
          source .env.${{ inputs.ENVIRONMENT }} ${{ inputs.DB_OVERRIDE }}
          make invalidate_caches
